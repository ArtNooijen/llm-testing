# Configuration for LLM Testing Interface

# Ollama Configuration
ollama:
  host: "drutus"  # drutus via Tailscale
  port: 11434
  model: "mistral:7b"
  timeout: 30  # seconds

# CLI Configuration
cli:
  welcome_message: "Welcome to LLM Testing Interface!"
  prompt: "You: "
  exit_commands: ["/exit", "/quit", "/q"]
  clear_commands: ["/clear", "/cls"]